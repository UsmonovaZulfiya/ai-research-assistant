{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6f773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (1.52.2)\n",
      "Requirement already satisfied: langchain in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (0.3.13)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: python_dotenv in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pypdf in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from pypdf) (4.12.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from faiss-cpu) (1.26.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: scholarly in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (1.7.11)\n",
      "Requirement already satisfied: arrow in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (4.12.2)\n",
      "Requirement already satisfied: bibtexparser in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (1.4.2)\n",
      "Requirement already satisfied: deprecated in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (1.2.14)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (1.5.1)\n",
      "Requirement already satisfied: free-proxy in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (1.1.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (0.27.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (1.0.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (2.31.0)\n",
      "Requirement already satisfied: selenium in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (4.25.0)\n",
      "Requirement already satisfied: sphinx-rtd-theme in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from scholarly) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from arrow->scholarly) (2.8.2)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from arrow->scholarly) (2.9.0.20241003)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from beautifulsoup4->scholarly) (2.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from bibtexparser->scholarly) (3.0.9)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from deprecated->scholarly) (1.16.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from free-proxy->scholarly) (4.9.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpx->scholarly) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpx->scholarly) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpx->scholarly) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpx->scholarly) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpx->scholarly) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpcore==1.*->httpx->scholarly) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from requests[socks]->scholarly) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from requests[socks]->scholarly) (1.26.16)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from requests[socks]->scholarly) (1.7.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from selenium->scholarly) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from selenium->scholarly) (0.11.1)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from selenium->scholarly) (1.8.0)\n",
      "Requirement already satisfied: sphinx<9,>=6 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx-rtd-theme->scholarly) (8.1.3)\n",
      "Requirement already satisfied: docutils<0.22,>0.18 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx-rtd-theme->scholarly) (0.21.2)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx-rtd-theme->scholarly) (4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from python-dateutil>=2.7.0->arrow->scholarly) (1.16.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.0.0)\n",
      "Requirement already satisfied: Jinja2>=3.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.17 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.18.0)\n",
      "Requirement already satisfied: snowballstemmer>=2.2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.13 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.16.0)\n",
      "Requirement already satisfied: alabaster>=0.7.14 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (1.0.0)\n",
      "Requirement already satisfied: imagesize>=1.3 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (1.4.1)\n",
      "Requirement already satisfied: packaging>=23.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (24.1)\n",
      "Requirement already satisfied: tomli>=2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.0.1)\n",
      "Requirement already satisfied: colorama>=0.4.6 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (0.4.6)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from trio~=0.17->selenium->scholarly) (1.0.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from trio-websocket~=0.9->selenium->scholarly) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium->scholarly) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from Jinja2>=3.1->sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (5.4.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (3.5.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.115.3)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.4.2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.26.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (1.26.0)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (3.10.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (10.0.1)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (2.9.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.0.12)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.7.1)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.1.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.41.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio) (0.32.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio-client==1.4.2->gradio) (2023.12.2)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from gradio-client==1.4.2->gradio) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (1.26.16)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\miniconda3\\envs\\csml\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai langchain\n",
    "! pip install python_dotenv\n",
    "! pip install --quiet -U langchain_openai langchain_core langchain_community\n",
    "! pip install pypdf\n",
    "! pip install faiss-cpu\n",
    "! pip install scholarly\n",
    "! pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d62d3ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8184965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Empty request\"}')\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "def chat_with_model(user_input):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        HumanMessage(content=user_input)\n",
    "    ]\n",
    "    \n",
    "    response = openai_model(messages)\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=chat_with_model,\n",
    "    inputs=gr.Textbox(lines=2, label=\"Enter your question\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Chat with AI Assistant\",\n",
    "    description=\"Ask questions and receive helpful responses from the AI assistant.\"\n",
    ")\n",
    "\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e614cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9320\\160970845.py:26: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "from scholarly import scholarly\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def download_pdf(url, filename):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  \n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return f\"Downloaded PDF: {filename}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to download PDF: {e}\"\n",
    "\n",
    "global_vector_store = None\n",
    "\n",
    "def store_pdf_in_vector_space(filename):\n",
    "    global global_vector_store  \n",
    "    loader = PyPDFLoader(filename)\n",
    "    documents = loader.load()\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    global_vector_store = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "    global_vector_store.save_local(\"vector_store\")\n",
    "    return \"PDF successfully stored in vector space.\"\n",
    "\n",
    "def research_assistant(query, download_and_store):\n",
    "    try:\n",
    "        search_query = scholarly.search_pubs(query)\n",
    "        paper = next(search_query)\n",
    "\n",
    "        title = paper.get('bib', {}).get('title', 'Title not available')\n",
    "        abstract = paper.get('bib', {}).get('abstract', 'Abstract not available')\n",
    "        authors = paper.get('bib', {}).get('author', 'Authors not available')\n",
    "        pub_year = paper.get('bib', {}).get('pub_year', 'Publication year not available')\n",
    "        pub_url = paper.get('pub_url', 'URL not available')\n",
    "\n",
    "        if isinstance(authors, list):\n",
    "            authors = ', '.join(authors)\n",
    "\n",
    "        result = f\"Title: {title}\\n\\nAbstract: {abstract}\\n\\nAuthors: {authors}\\n\\nPublication Year: {pub_year}\\n\\nFull Paper URL: {pub_url}\"\n",
    "\n",
    "        if download_and_store and pub_url.endswith(\".pdf\"): \n",
    "            pdf_filename = \"downloaded_paper.pdf\"\n",
    "            download_status = download_pdf(pub_url, pdf_filename)\n",
    "\n",
    "            if \"Downloaded PDF\" in download_status:\n",
    "                store_status = store_pdf_in_vector_space(pdf_filename)\n",
    "                result += f\"\\n\\n{download_status}\\n{store_status}\"\n",
    "            else:\n",
    "                result += f\"\\n\\n{download_status}\"\n",
    "        elif download_and_store:\n",
    "            result += \"\\n\\nThe paper is not directly available as a PDF.\"\n",
    "\n",
    "    except StopIteration:\n",
    "        result = \"No results found for the query.\"\n",
    "\n",
    "    return result\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=research_assistant,  \n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, label=\"Enter Your Query\"), \n",
    "        gr.Checkbox(label=\"Download and store full text (PDF)\")  \n",
    "    ],\n",
    "    outputs=\"text\",          \n",
    "    title=\"AI Research Assistant with PDF Storage\",\n",
    "    description=\"Enter your search query to find relevant research papers and summaries. Optionally download the full text (PDF) and store it in a vector space.\"\n",
    ")\n",
    "\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74019dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=openai_model,           \n",
    "    chain_type=\"stuff\",         \n",
    "    retriever=global_vector_store.as_retriever()  \n",
    ")\n",
    "\n",
    "def query_retriever(question):\n",
    "    response = qa_chain.run(question)\n",
    "    return response\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=query_retriever,         \n",
    "    inputs=gr.Textbox(lines=2, label=\"Enter Your Question\"), \n",
    "    outputs=\"text\",             \n",
    "    title=\"AI Research Assistant\",  \n",
    "    description=\"Ask questions about your research papers and get summarized answers from the AI.\"\n",
    ")\n",
    "\n",
    "interface.launch()\n",
    "\n",
    "# \"What are the key findings of the research paper?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc81fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9320\\1946687300.py:21: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  summarization_chain = LLMChain(llm=openai_model, prompt=prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9320\\1946687300.py:24: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vector_store = FAISS.load_local(\"vector_store\", OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "summarization_prompt = \"\"\"\n",
    "Summarize the following document section in a concise and clear manner:\n",
    "\n",
    "{document}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"document\"], template=summarization_prompt)\n",
    "\n",
    "summarization_chain = LLMChain(llm=openai_model, prompt=prompt)\n",
    "\n",
    "def summarize_query(query):\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        return \"No relevant documents found.\"\n",
    "\n",
    "    document_content = retrieved_docs[0].page_content\n",
    "    summary = summarization_chain.run(document=document_content)\n",
    "\n",
    "    return summary\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=summarize_query,  \n",
    "    inputs=gr.Textbox(lines=2, label=\"Enter your query\"),  \n",
    "    outputs=\"text\",  \n",
    "    title=\"Document Summarization Assistant\",\n",
    "    description=\"Enter a query to summarize the relevant sections of your documents.\"\n",
    ")\n",
    "\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bea26994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents: ['Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d modeldffh d kdvPdropϵlstrain PPL BLEU params\\nsteps (dev) (dev)×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B)16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\nIn Table 3 rows (B), we observe that reducing the attention key size dkhurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [ 8], and observe nearly identical\\nresults to the base model.\\n7 Conclusion\\nIn this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor .\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\n9', 'Figure 1: The Transformer - model architecture.\\nwise fully connected feed-forward network. We employ a residual connection [ 10] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm( x+ Sublayer( x)), where Sublayer(x)is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512 .\\nDecoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position ican depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\n3', 'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.', 'Recurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstatesht, as a function of the previous hidden state ht−1and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsigniﬁcant improvements in computational efﬁciency through factorization tricks [ 18] and conditional\\ncomputation [ 26], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [ 2,16]. In all but a few cases [ 22], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [ 15] and ConvS2S [ 8], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difﬁcult to learn dependencies between distant positions [ 11]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,29].\\nHere, the encoder maps an input sequence of symbol representations (x1,...,x n)to a sequence\\nof continuous representations z= (z1,...,z n). Given z, the decoder then generates an output\\nsequence (y1,...,y m)of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\n2']\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Retrieved Documents: ['Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d modeldffh d kdvPdropϵlstrain PPL BLEU params\\nsteps (dev) (dev)×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B)16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\nIn Table 3 rows (B), we observe that reducing the attention key size dkhurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [ 8], and observe nearly identical\\nresults to the base model.\\n7 Conclusion\\nIn this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor .\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\n9', 'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.', 'Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModelBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [15] 23.75\\nDeep-Att + PosUnk [32] 39.2 1.0·1020\\nGNMT + RL [31] 24.6 39.92 2.3·10191.4·1020\\nConvS2S [8] 25.16 40.46 9.6·10181.5·1020\\nMoE [26] 26.03 40.56 2.0·10191.2·1020\\nDeep-Att + PosUnk Ensemble [32] 40.4 8.0·1020\\nGNMT + RL Ensemble [31] 26.30 41.16 1.8·10201.1·1021\\nConvS2S Ensemble [8] 26.36 41.29 7.7·10191.2·1021\\nTransformer (base model) 27.3 38.1 3.3·1018\\nTransformer (big) 28.4 41.0 2.3·1019\\nLabel Smoothing During training, we employed label smoothing of value ϵls= 0.1[30]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The conﬁguration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5days on 8P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop= 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4and length penalty α= 0.6[31]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [31].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of ﬂoating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision ﬂoating-point capacity of each GPU5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8', 'Recurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstatesht, as a function of the previous hidden state ht−1and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsigniﬁcant improvements in computational efﬁciency through factorization tricks [ 18] and conditional\\ncomputation [ 26], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [ 2,16]. In all but a few cases [ 22], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [ 15] and ConvS2S [ 8], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difﬁcult to learn dependencies between distant positions [ 11]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,29].\\nHere, the encoder maps an input sequence of symbol representations (x1,...,x n)to a sequence\\nof continuous representations z= (z1,...,z n). Given z, the decoder then generates an output\\nsequence (y1,...,y m)of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\n2']\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Empty request\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "vector_store = FAISS.load_local(\"vector_store\", OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "\n",
    "# memory to store conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# prompt for generating follow-up questions\n",
    "question_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"],\n",
    "    template=\"Given the conversation so far: {chat_history}, and the question: {question}, generate a follow-up question if necessary.\"\n",
    ")\n",
    "\n",
    "question_generator = LLMChain(\n",
    "    llm=openai_model,\n",
    "    prompt=question_prompt\n",
    ")\n",
    "\n",
    "qa_chain = load_qa_chain(llm=openai_model, chain_type=\"stuff\")\n",
    "\n",
    "# conversational retrieval chain with the required components\n",
    "conversation_chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain=qa_chain,\n",
    "    question_generator=question_generator,\n",
    "    verbose=True \n",
    ")\n",
    "\n",
    "def chat_with_agent(user_input):\n",
    "    retrieved_docs = retriever.get_relevant_documents(user_input)\n",
    "    print(\"Retrieved Documents:\", [doc.page_content for doc in retrieved_docs])  # Print retrieved document content\n",
    "    \n",
    "    response = conversation_chain.invoke({\"question\": user_input})\n",
    "    return response['answer']\n",
    "\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=chat_with_agent,\n",
    "    inputs=gr.Textbox(lines=2, label=\"Enter your query\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Conversational Agent with Document Focus\",\n",
    "    description=\"Chat with an AI assistant that retrieves information from documents while maintaining conversation context.\"\n",
    ")\n",
    "\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
